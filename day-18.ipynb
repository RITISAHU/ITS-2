{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
      "Requirement already satisfied: nltk in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ritik\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: comtypes in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyttsx3) (1.2.0)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\ritik\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\ritik\\appdata\\roaming\\python\\python310\\site-packages (from pyttsx3) (306)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install SpeechRecognition\n",
    "!python -m pip install nltk\n",
    "!python -m pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import nltk\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from time import sleep\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "vid = cv2.VideoCapture(index = 0)\n",
    "while True:\n",
    "    ack, img = vid.read()\n",
    "    if ack:\n",
    "        people, weights = hog.detectMultiScale(\n",
    "            cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), winStride = (15,15),\n",
    "        )\n",
    "        for x,y,w,h in people:\n",
    "            cv2.rectangle(\n",
    "                img, pt1=(x,y), pt2=(x+w,y+h), color=(0,0,255), thickness=5,\n",
    "            )\n",
    "        sleep(0.1)\n",
    "        cv2.imshow('Preview',img)\n",
    "        if cv2.waitKey(delay = 1) == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows(); cv2.waitKey(1)\n",
    "vid.release()\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Based Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "tts = pyttsx3.init()\n",
    "tts.setProperty('rate',200)\n",
    "tts.say(\"hello, ritik sahu i am speaking for you from your computer\")\n",
    "tts.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "a = pyttsx3.init()\n",
    "a.setProperty('rate',200)\n",
    "a.say(\"hello, ritik sahu i am speaking for you from your computer\")\n",
    "a.runAndWait()\n",
    "a.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mwith\u001b[39;00m sr\u001b[39m.\u001b[39mMicrophone() \u001b[39mas\u001b[39;00m mic:\n\u001b[0;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSpeak\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     audio \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39;49mlisten(mic)\n\u001b[0;32m     13\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m         text \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39mrecognize_google(audio)\n",
      "File \u001b[1;32mc:\\Users\\RITIK\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\RITIK\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\RITIK\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize the text-to-speech engine\n",
    "tts = pyttsx3.init()\n",
    "\n",
    "rec = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as mic:\n",
    "    print('Speak')\n",
    "    audio = rec.listen(mic)\n",
    "    \n",
    "    try:\n",
    "        text = rec.recognize_google(audio)\n",
    "        print('You said:', text)\n",
    "        \n",
    "        # Use the initialized tts engine to speak the recognized text\n",
    "        tts.say('You said: ' + text)\n",
    "        tts.runAndWait()\n",
    "    except Exception as err:\n",
    "        print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak:\n",
      "hey google\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "iphone\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "mar ja\n"
     ]
    }
   ],
   "source": [
    "import webbrowser as web\n",
    "rec = sr.Recognizer()\n",
    "flag = False\n",
    "while True:\n",
    "    with sr.Microphone() as mic:\n",
    "        print('Speak:')\n",
    "        audio = rec.listen(mic,phrase_time_limit=3,timeout=5)\n",
    "        try:\n",
    "            text = rec.recognize_google(audio).lower()\n",
    "            print(text)\n",
    "            if flag == True:\n",
    "                if 'search' in text:\n",
    "                    item = text.split('search')[-1].strip()\n",
    "                    flipkart_url = 'https://flipkart.com/search?q='\n",
    "                    amazon_url = 'https://amazon.in/s?k='\n",
    "                    web.open_new(flipkart_url + item)\n",
    "                    web.open_new_tab(amazon_url + item)                    \n",
    "                flag = False\n",
    "\n",
    "            if 'hey google' in text:\n",
    "                flag = True\n",
    "            elif 'mar ja' in text: \n",
    "                break\n",
    "\n",
    "            # if flag == False:\n",
    "            #     print('You said:',text)\n",
    "            # tts.say(text)\n",
    "            # tts.runAndWait()\n",
    "        except Exception as err:\n",
    "            print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chat.util import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q1 = r'(.*)your name (.*)company(.*)'\n",
    "a1 = ['my name is chatchat','I am chatchat']\n",
    "q2 = r'kya aaj kuch achha hoga'\n",
    "a2 = ['haan','mujhe kya pata','mein kyo batau']\n",
    "qa_pair = [\n",
    "    [q1,a1],\n",
    "    [q2,a2],\n",
    "]\n",
    "cb = Chat(qa_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ques = input('enter ques:').lower()\n",
    "resp = cb.respond(ques)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chat.util import Chat\n",
    "\n",
    "q1 = r'(.*)your name (.*)company(.*)'\n",
    "a1 = ['my name is chatchat', 'I am chatchat']\n",
    "q2 = r'kya aaj kuch achha hoga'\n",
    "a2 = ['haan', 'mujhe kya pata', 'mein kyo batau']\n",
    "qa_pair = [\n",
    "    [q1, a1],\n",
    "    [q2, a2],\n",
    "]\n",
    "cb = Chat(qa_pair)\n",
    "\n",
    "ques = input('Enter question: ').lower()\n",
    "resp = cb.respond(ques)\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Regular Expressions\n",
    "#######################\n",
    "# ()      Capture & Group\n",
    "# .       Any character (except new line)\n",
    "# *       zero or more occurrences\n",
    "# |       or\n",
    "# []      set of characters\n",
    "# a-z\n",
    "# A-Z\n",
    "# 0-9\n",
    "# ^       starting with\n",
    "# $       ends with\n",
    "# ?       zero or one occurrence\n",
    "# +       one or more occurrence\n",
    "# {}      exact number of occurrence\n",
    "# \\w      only word characters\n",
    "# \\W      not word characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak:\n",
      "hey google\n",
      "name 'flag' is not defined\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "iphone 13 search\n",
      "name 'flag' is not defined\n",
      "Speak:\n",
      "mar ja\n",
      "name 'flag' is not defined\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "independence\n",
      "name 'flag' is not defined\n",
      "Speak:\n",
      "free define apk\n",
      "name 'flag' is not defined\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m sr\u001b[39m.\u001b[39mMicrophone() \u001b[39mas\u001b[39;00m mic:\n\u001b[0;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSpeak:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m     audio \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39;49mlisten(mic,phrase_time_limit\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,timeout\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     20\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m         text \u001b[39m=\u001b[39m rec\u001b[39m.\u001b[39mrecognize_google(audio)\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\RITIK\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:523\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    521\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    525\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\RITIK\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py:199\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\RITIK\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nltk.chat.util import Chat\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "q1 = r'(.*)your name (.*)company(.*)'\n",
    "a1 = ['my name is chatchat','I am chatchat']\n",
    "q2 = r'kya aaj kuch achha hoga'\n",
    "a2 = ['haan','mujhe kya pata','mein kyo batau']\n",
    "qa_pair = [\n",
    "    [q1,a1],\n",
    "    [q2,a2],\n",
    "]\n",
    "cb = Chat(qa_pair)\n",
    "tts = pyttsx3.init()\n",
    "rec = sr.Recognizer()\n",
    "while True:\n",
    "    with sr.Microphone() as mic:\n",
    "        print('Speak:')\n",
    "        audio = rec.listen(mic,phrase_time_limit=3,timeout=5)\n",
    "        try:\n",
    "            text = rec.recognize_google(audio).lower()\n",
    "            print(text)\n",
    "            if flag == True:\n",
    "                if 'search' in text:\n",
    "                    item = text.split('search')[-1].strip()\n",
    "                    flipkart_url = 'https://flipkart.com/search?q='\n",
    "                    amazon_url = 'https://amazon.in/s?k='\n",
    "                    web.open_new(flipkart_url + item)\n",
    "                    web.open_new_tab(amazon_url + item)\n",
    "                else:\n",
    "                    resp = cb.respond(text)\n",
    "                    if resp == None:\n",
    "                        tts.say('Sorry, I dont know')\n",
    "                    else:\n",
    "                        tts.say(resp)\n",
    "                    tts.runAndWait()\n",
    "                flag = False\n",
    "            if 'hey google' in text:\n",
    "                flag = True\n",
    "            elif 'mar ja' in text: \n",
    "                break\n",
    "        except Exception as err:\n",
    "            print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak:\n",
      "\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "hey google\n",
      "Speak:\n",
      "iphone 13\n",
      "Speak:\n",
      "iphone 13 search\n",
      "Speak:\n",
      "\n",
      "Speak:\n",
      "mar ja\n"
     ]
    }
   ],
   "source": [
    "from nltk.chat.util import Chat\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import webbrowser as web\n",
    "\n",
    "q1 = r'(.*)your name (.*)company(.*)'\n",
    "a1 = ['my name is chatchat', 'I am chatchat']\n",
    "q2 = r'kya aaj kuch achha hoga'\n",
    "a2 = ['haan', 'mujhe kya pata', 'mein kyo batau']\n",
    "qa_pair = [\n",
    "    [q1, a1],\n",
    "    [q2, a2],\n",
    "]\n",
    "cb = Chat(qa_pair)\n",
    "tts = pyttsx3.init()\n",
    "rec = sr.Recognizer()\n",
    "flag = False  # Initialize the flag variable\n",
    "while True:\n",
    "    with sr.Microphone() as mic:\n",
    "        print('Speak:')\n",
    "        audio = rec.listen(mic, phrase_time_limit=3, timeout=5)\n",
    "        try:\n",
    "            text = rec.recognize_google(audio).lower()\n",
    "            print(text)\n",
    "            if flag:\n",
    "                if 'search' in text:\n",
    "                    item = text.split('search')[-1].strip()\n",
    "                    flipkart_url = 'https://flipkart.com/search?q='\n",
    "                    amazon_url = 'https://amazon.in/s?k='\n",
    "                    web.open_new(flipkart_url + item)\n",
    "                    web.open_new_tab(amazon_url + item)\n",
    "                else:\n",
    "                    resp = cb.respond(text)\n",
    "                    if resp is None:\n",
    "                        tts.say('Sorry, I don\\'t know')\n",
    "                    else:\n",
    "                        tts.say(resp)\n",
    "                    tts.runAndWait()\n",
    "                flag = False\n",
    "            if 'hey google' in text:\n",
    "                flag = True\n",
    "            elif 'mar ja' in text:\n",
    "                break\n",
    "        except Exception as err:\n",
    "            print(err)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
